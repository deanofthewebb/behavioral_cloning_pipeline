{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset - Load Data\n",
    "\n",
    "Start by importing the simulator data from the training_data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset Parameters\n",
    "DRIVING_LOG_CSV = 'full_driving_log.csv'\n",
    "MODEL_DATA = 'model.h5'\n",
    "\n",
    "# Image Augmentation\n",
    "CORRECTION_ANGLE = 0.25\n",
    "NB_AUGMENTED_SAMPLES = 20000\n",
    "\n",
    "# Image Processing\n",
    "DEFAULT_LENGTH, DEFAULT_WIDTH, DEFAULT_DEPTH = (320, 160, 3)\n",
    "DEFAULT_RESOLUTION = (DEFAULT_LENGTH, DEFAULT_WIDTH, DEFAULT_DEPTH) if DEFAULT_DEPTH > 1 else (DEFAULT_LENGTH, DEFAULT_WIDTH)\n",
    "DATASET_DIRECTORY = 'merged_data/'\n",
    "\n",
    "# Validation Dataset\n",
    "VALIDATION_PORTION = 0.222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drive_data = pd.read_csv(os.path.join(DATASET_DIRECTORY,DRIVING_LOG_CSV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>steering</th>\n",
       "      <th>throttle</th>\n",
       "      <th>brake</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG/center_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.148290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG/center_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.879630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.453011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.438419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.418236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   center  \\\n",
       "0  IMG/center_2016_12_01_13_30_48_287.jpg   \n",
       "1  IMG/center_2016_12_01_13_30_48_404.jpg   \n",
       "2  IMG/center_2016_12_01_13_31_12_937.jpg   \n",
       "3  IMG/center_2016_12_01_13_31_13_037.jpg   \n",
       "4  IMG/center_2016_12_01_13_31_13_177.jpg   \n",
       "\n",
       "                                    left  \\\n",
       "0   IMG/left_2016_12_01_13_30_48_287.jpg   \n",
       "1   IMG/left_2016_12_01_13_30_48_404.jpg   \n",
       "2   IMG/left_2016_12_01_13_31_12_937.jpg   \n",
       "3   IMG/left_2016_12_01_13_31_13_037.jpg   \n",
       "4   IMG/left_2016_12_01_13_31_13_177.jpg   \n",
       "\n",
       "                                    right  steering  throttle  brake  \\\n",
       "0   IMG/right_2016_12_01_13_30_48_287.jpg       0.0       0.0    0.0   \n",
       "1   IMG/right_2016_12_01_13_30_48_404.jpg       0.0       0.0    0.0   \n",
       "2   IMG/right_2016_12_01_13_31_12_937.jpg       0.0       0.0    0.0   \n",
       "3   IMG/right_2016_12_01_13_31_13_037.jpg       0.0       0.0    0.0   \n",
       "4   IMG/right_2016_12_01_13_31_13_177.jpg       0.0       0.0    0.0   \n",
       "\n",
       "       speed  \n",
       "0  22.148290  \n",
       "1  21.879630  \n",
       "2   1.453011  \n",
       "3   1.438419  \n",
       "4   1.418236  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drive_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset - Image Augmentation\n",
    "\n",
    "Image Augmentation techniques as described by Vivek Yadav (https://chatbotslife.com/using-augmentation-to-mimic-human-driving-496b569760a9#.jao9k5lb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def read_csv(filepath, num_features=7, delimiter=';'):\n",
    "    data_array = np.array(np.zeros(shape=num_features), ndmin=2)    \n",
    "    with open(filepath, newline='') as csvfile:\n",
    "        annotations_reader = csv.reader(csvfile, delimiter=delimiter, quotechar='|')\n",
    "        for row in annotations_reader:\n",
    "            data_array = np.vstack((data_array, np.array(row, ndmin=2)))\n",
    "    return data_array[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def resize_image(image):      \n",
    "    shape = image.shape\n",
    "    # Crop numpy array of image to remove extraneous pixels\n",
    "    image = image[math.floor(shape[0]/5):shape[0]-25, 0:shape[1]]\n",
    "    if (shape[0] != DEFAULT_RESOLUTION[1] or shape[1] != DEFAULT_RESOLUTION[0]):\n",
    "        # Resize numpy array, note numpy arrays are formatted with (ROW, COL, CH)\n",
    "        image = cv2.resize(image,(DEFAULT_RESOLUTION[1],DEFAULT_RESOLUTION[0]), interpolation=cv2.INTER_AREA)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_brightness_camera_images(image):\n",
    "    v_ch = 2\n",
    "    image1 = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    random_light = .25+np.random.uniform()\n",
    "    image1[:,:,v_ch] = image1[:,:,v_ch]*random_light\n",
    "    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)\n",
    "    return image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def translate_image(image,steer,trans_range):\n",
    "    shape = image.shape\n",
    "    # Translation\n",
    "    delta_x = trans_range*np.random.uniform()-trans_range/2\n",
    "    steering_angle = steer + delta_x/trans_range*2*.2\n",
    "    delta_y = 40*np.random.uniform()-40/2\n",
    "    Trans_M = np.float32([[1,0,delta_x],[0,1,delta_y]])\n",
    "    translated_image = cv2.warpAffine(image,Trans_M,(shape[0], shape[1]))    \n",
    "    return translated_image,steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def randomly_add_shadow_effect(image):\n",
    "    top_y = DEFAULT_LENGTH*np.random.uniform()\n",
    "    top_x = 0\n",
    "    bot_x = DEFAULT_WIDTH\n",
    "    bot_y = DEFAULT_LENGTH*np.random.uniform()\n",
    "    s_ch = 1\n",
    "    image_hls = cv2.cvtColor(image,cv2.COLOR_RGB2HLS) #HLS\n",
    "    shadow_mask = 0*image_hls[:,:,1]\n",
    "    X_m = np.mgrid[0:image.shape[0],0:image.shape[1]][0]\n",
    "    Y_m = np.mgrid[0:image.shape[0],0:image.shape[1]][1]\n",
    "    shadow_mask[((X_m-top_x)*(bot_y-top_y) -(bot_x - top_x)*(Y_m-top_y) >=0)]=1\n",
    "    if np.random.randint(2)==1:\n",
    "        random_bright = .5\n",
    "        cond1 = shadow_mask==1\n",
    "        cond0 = shadow_mask==0\n",
    "        if np.random.randint(2)==1:\n",
    "            image_hls[:,:,s_ch][cond1] = image_hls[:,:,s_ch][cond1]*random_bright\n",
    "        else:\n",
    "            image_hls[:,:,s_ch][cond0] = image_hls[:,:,s_ch][cond0]*random_bright    \n",
    "    return cv2.cvtColor(image_hls,cv2.COLOR_HLS2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomly_flip_image(image, measurement):\n",
    "    if (np.random.randint(2) == 0):\n",
    "        image = cv2.flip(image,1)\n",
    "        measurement = -measurement\n",
    "    return image, measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_image(line_data, features):    \n",
    "    random_index = np.random.randint(3)    \n",
    "    if (random_index == 0):\n",
    "        filepath = line_data['left'][0].strip()\n",
    "        shifted_ang = CORRECTION_ANGLE\n",
    "    if (random_index == 1):\n",
    "        filepath = line_data['center'][0].strip()\n",
    "        shifted_ang = 0.\n",
    "    if (random_index == 2):\n",
    "        filepath = line_data['right'][0].strip()\n",
    "        shifted_ang = -CORRECTION_ANGLE\n",
    "        \n",
    "    #Scale Steering Angle back up\n",
    "    mean, std = features['steering']\n",
    "    #print('std',std)\n",
    "    steering_angle = float(line_data['steering'][0])*std + mean + shifted_ang\n",
    "            \n",
    "    full_path = os.path.join(DATASET_DIRECTORY, filepath.strip())\n",
    "    if os.path.exists(full_path):\n",
    "        image = cv2.imread(full_path)\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        #print('image before translate:', image.shape)\n",
    "        image, steering_angle = translate_image(image, steering_angle, 100)\n",
    "        #print('image before augment_brightness:', image.shape)\n",
    "        image = augment_brightness_camera_images(image)\n",
    "        #print('image before resize:', image.shape)\n",
    "        #image = resize_image(image)\n",
    "        image = np.array(image)\n",
    "        #print('image after array and before random flip:', image.shape)\n",
    "        image, steering_angle = randomly_flip_image(image, steering_angle)\n",
    "\n",
    "        #image = randomly_add_shadow_effect(image)\n",
    "\n",
    "    else:\n",
    "        print('Image Path:', full_path, \"does not exist\")\n",
    "\n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling target variables\n",
    "To make training the network easier, we'll standardize each of the continuous variables. That is, we'll shift and scale the variables such that they have zero mean and a standard deviation of 1.\n",
    "\n",
    "The scaling factors are saved so we can go backwards when we use the network for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scaled_features(target_fields = ['steering', 'throttle', 'brake', 'speed']):\n",
    "    data=pd.read_csv(os.path.join(DATASET_DIRECTORY, DRIVING_LOG_CSV))\n",
    "    # Store scalings in a dictionary for converting back later\n",
    "    scaled_feats = {}\n",
    "    \n",
    "    for each in target_fields:\n",
    "        mean, std = data[each].mean(), data[each].std()\n",
    "\n",
    "        scaled_feats[each] = [mean, std]\n",
    "        data.loc[:, each] = (data[each] - mean)/std\n",
    "    return data, scaled_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def generate_augmented_training_batch(pr_threshold = 1, batch_size = 256):\n",
    "    target_fields = ['steering', 'throttle', 'brake', 'speed']\n",
    "    data, scaled_feats = get_scaled_features(target_fields)\n",
    "    # Separate the data by features and targets\n",
    "    camera_data, sensor_data = data.drop(target_fields, axis=1), data[target_fields]\n",
    "    batch_images = np.zeros((batch_size, DEFAULT_RESOLUTION[1], DEFAULT_RESOLUTION[0], DEFAULT_RESOLUTION[2]))\n",
    "    batch_measurements = np.zeros(batch_size)\n",
    "    while 1:\n",
    "        for i_batch in range(batch_size):\n",
    "            index = np.random.randint(len(data)) \n",
    "            line_data = data.iloc[[index]].reset_index()\n",
    "            keep_pr = 0\n",
    "            while keep_pr == 0:\n",
    "                image, measurement = preprocess_image(line_data, scaled_feats)\n",
    "                pr_unif = np.random\n",
    "                if (abs(measurement) < .1):\n",
    "                    pr_val = np.random.uniform()\n",
    "                    if (pr_val > pr_threshold):\n",
    "                        keep_pr = 1\n",
    "                else:\n",
    "                    keep_pr = 1\n",
    "            batch_images[i_batch] = image\n",
    "            batch_measurements[i_batch] = measurement\n",
    "        yield batch_images, batch_measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Network - Modified Comma AI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.python.control_flow_ops = tf\n",
    "# from keras.models import Model\n",
    "# import keras.backend as K\n",
    "# from keras.layers import Input\n",
    "# from keras.layers.core import Flatten, Dense, Dropout, Activation, Lambda\n",
    "# from keras.layers.convolutional import Convolution2D\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# from keras.layers.advanced_activations import LeakyReLU\n",
    "# from keras.optimizers import SGD, Adam\n",
    "# from keras.layers import Cropping2D\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.utils import np_utils\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "# import sys\n",
    "\n",
    "# #Hyperparameters\n",
    "# batch_size = 256\n",
    "# nb_epochs = 2\n",
    "# top_crop = 65\n",
    "# bottom_crop = 25\n",
    "\n",
    "# inputs = Input(shape=(DEFAULT_RESOLUTION[1], DEFAULT_RESOLUTION[0], DEFAULT_RESOLUTION[2]))\n",
    "# crop = Cropping2D(cropping=((top_crop,bottom_crop), (0,0)))(inputs)\n",
    "# lambda_1 = Lambda(lambda x: x/127.5 - 1.)(inputs)\n",
    "# conv_1 = Convolution2D(16, 8, 8, init='glorot_uniform',\n",
    "#                              subsample=(4,4),border_mode='same')(lambda_1)\n",
    "# lrelu_1 = LeakyReLU()(conv_1)\n",
    "# conv_2 = Convolution2D(32, 5, 5, init='glorot_uniform',\n",
    "#                              subsample=(2,2),border_mode='same')(lrelu_1)\n",
    "# lrelu_2 = LeakyReLU()(conv_2)\n",
    "# conv_3 = Convolution2D(64, 5, 5, init='glorot_uniform',\n",
    "#                              subsample=(2,2),border_mode='same')(lrelu_1)\n",
    "# flatten = Flatten()(conv_3)\n",
    "# dropout_1 = Dropout(0.2)(flatten)\n",
    "# lrelu_3 = LeakyReLU()(dropout_1)\n",
    "# fc_1 = Dense(512)(lrelu_3)\n",
    "# fc_2 = Dense(64)(fc_1)\n",
    "# fc_3 = Dense(16)(fc_2)\n",
    "# # dropout_2 = Dropout(0.5)(fc_1)\n",
    "# lrelu_4 = LeakyReLU()(fc_3)\n",
    "# predictions = Dense(1, activation='tanh')(lrelu_4)\n",
    "\n",
    "\n",
    "# # _, scaled_features = get_scaled_features(['steering'])\n",
    "# # mean, std = scaled_features['steering']\n",
    "# # mean = K.variable(value=mean)\n",
    "# # std_dev = K.variable(value=std)\n",
    "\n",
    "# # Merge([predictions, std_dev], mode='concat', concat_axis=1)\n",
    "# # predictions_2 = Lambda(lambda x: x*std_dev)(predictions)\n",
    "\n",
    "\n",
    "# # params = {'mean':mean, 'std':std_dev}\n",
    "\n",
    "# # lambda_layer_1 = Lambda(lambda x: scaled_steering(params)*x)(predictions)\n",
    "\n",
    "# # lambda_layer = Lambda(lambda x: x*std_dev + mean)(predictions)\n",
    "# # outputs = lambda_layer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model = Model(input=inputs, output=predictions)\n",
    "# adam = Adam(lr=0.0007, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "# model.compile(loss='mse',\n",
    "#              optimizer=adam,\n",
    "#              metrics=['msle'])\n",
    "# print(model.summary())\n",
    "\n",
    "# callback1 = ModelCheckpoint('weights.{epoch:02d}-{loss:.2f}.hdf5', monitor='loss',\n",
    "#                             verbose=0, save_best_only=False, mode='auto')        \n",
    "# pr_threshold = 1\n",
    "# for e in range(nb_epochs):\n",
    "#     generator = generate_augmented_training_batch(pr_threshold, batch_size)\n",
    "#     #validation_generator = generate_augmented_training_batch(pr_threshold,batch_size)\n",
    "#     #validation_size = int(NB_AUGMENTED_SAMPLES*VALIDATION_PORTION)\n",
    "    \n",
    "# #     model.fit_generator(generator, samples_per_epoch=NB_AUGMENTED_SAMPLES,\n",
    "# #                     nb_epoch=1, callbacks=[callback1], validation_data=validation_generator,\n",
    "# #                    nb_val_samples = validation_size, verbose=1)\n",
    "#     model.fit_generator(generator, samples_per_epoch=NB_AUGMENTED_SAMPLES, \n",
    "#                         nb_epoch=1, callbacks=[callback1], verbose=1)\n",
    "#     pr_threshold = 1/((e+1)*1.)\n",
    "\n",
    "# model.save(MODEL_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 160, 320, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 160, 320, 3)   12          input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_4 (LeakyReLU)          (None, 160, 320, 3)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 160, 320, 32)  896         leakyrelu_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_5 (LeakyReLU)          (None, 160, 320, 32)  0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 160, 320, 32)  9248        leakyrelu_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_6 (LeakyReLU)          (None, 160, 320, 32)  0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 160, 320, 64)  18496       leakyrelu_6[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_7 (LeakyReLU)          (None, 160, 320, 64)  0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 160, 320, 64)  36928       leakyrelu_7[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_8 (LeakyReLU)          (None, 160, 320, 64)  0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 160, 320, 128) 73856       leakyrelu_8[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_9 (LeakyReLU)          (None, 160, 320, 128) 0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 160, 320, 128) 147584      leakyrelu_9[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_10 (LeakyReLU)         (None, 160, 320, 128) 0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 80, 160, 128)  0           leakyrelu_10[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 80, 160, 128)  0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1638400)       0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 512)           838861312   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 64)            32832       dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 16)            1040        dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             17          dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 839,182,221\n",
      "Trainable params: 839,182,221\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import Cropping2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import sys\n",
    "\n",
    "\n",
    "#Hyperparameters\n",
    "batch_size = 256\n",
    "nb_epochs = 5\n",
    "top_crop = 65\n",
    "bottom_crop = 25\n",
    "\n",
    "inputs = Input(shape=(DEFAULT_RESOLUTION[1], DEFAULT_RESOLUTION[0], DEFAULT_RESOLUTION[2]))\n",
    "\n",
    "# 3 1x1 filters\n",
    "conv_1 = Convolution2D(3, 1, 1, init='glorot_uniform',border_mode='same')(inputs)\n",
    "lrelu_1 = LeakyReLU()(conv_1)\n",
    "\n",
    "\n",
    "# 3 convolutional blocks\n",
    "conv_2 = Convolution2D(32, 3, 3, init='glorot_uniform',border_mode='same')(lrelu_1)\n",
    "lrelu_2 = LeakyReLU()(conv_2)\n",
    "conv_2 = Convolution2D(32, 3, 3, init='glorot_uniform',border_mode='same')(lrelu_2)\n",
    "lrelu_2 = LeakyReLU()(conv_2)\n",
    "maxpool_1 = MaxPooling2D((2,2))(lrelu_2)\n",
    "dropout_1 = Dropout(0.5)(maxpool_1)\n",
    "\n",
    "\n",
    "conv_3 = Convolution2D(64, 3, 3, init='glorot_uniform',border_mode='same')(lrelu_2)\n",
    "lrelu_3 = LeakyReLU()(conv_3)\n",
    "conv_3 = Convolution2D(64, 3, 3, init='glorot_uniform',border_mode='same')(lrelu_3)\n",
    "lrelu_3 = LeakyReLU()(conv_3)\n",
    "maxpool_2 = MaxPooling2D((2,2))(lrelu_3)\n",
    "dropout_2 = Dropout(0.5)(maxpool_2)\n",
    "\n",
    "\n",
    "conv_4 = Convolution2D(128, 3, 3, init='glorot_uniform',border_mode='same')(lrelu_3)\n",
    "lrelu_4 = LeakyReLU()(conv_4)\n",
    "conv_4 = Convolution2D(128, 3, 3, init='glorot_uniform',border_mode='same')(lrelu_4)\n",
    "lrelu_4 = LeakyReLU()(conv_4)\n",
    "maxpool_3 = MaxPooling2D((2,2))(lrelu_4)\n",
    "dropout_3 = Dropout(0.5)(maxpool_3)\n",
    "\n",
    "\n",
    "flatten = Flatten()(dropout_3)\n",
    "fc_1 = Dense(512)(flatten)\n",
    "fc_2 = Dense(64)(fc_1)\n",
    "fc_3 = Dense(16)(fc_2)\n",
    "\n",
    "\n",
    "predictions = Dense(1, activation='tanh')(fc_3)\n",
    "\n",
    "model = Model(input=inputs, output=predictions)\n",
    "adam = Adam(lr=0.0007, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='mse',\n",
    "             optimizer=adam,\n",
    "             metrics=['msle'])\n",
    "print(model.summary())\n",
    "\n",
    "callback1 = ModelCheckpoint('weights.{epoch:02d}-{loss:.2f}.hdf5', monitor='loss',\n",
    "                            verbose=0, save_best_only=False, mode='auto')        \n",
    "pr_threshold = 1\n",
    "for e in range(nb_epochs):\n",
    "    generator = generate_augmented_training_batch(pr_threshold, batch_size)\n",
    "    #validation_generator = generate_augmented_training_batch(pr_threshold,batch_size)\n",
    "    #validation_size = int(NB_AUGMENTED_SAMPLES*VALIDATION_PORTION)\n",
    "    \n",
    "#     model.fit_generator(generator, samples_per_epoch=NB_AUGMENTED_SAMPLES,\n",
    "#                     nb_epoch=1, callbacks=[callback1], validation_data=validation_generator,\n",
    "#                    nb_val_samples = validation_size, verbose=1)\n",
    "    model.fit_generator(generator, samples_per_epoch=NB_AUGMENTED_SAMPLES, \n",
    "                        nb_epoch=1, callbacks=[callback1], verbose=1)\n",
    "    pr_threshold = 1/((e+1)*1.)\n",
    "\n",
    "model.save(MODEL_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [sdc_dev]",
   "language": "python",
   "name": "Python [sdc_dev]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
