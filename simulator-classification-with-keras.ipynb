{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset - Load Data\n",
    "\n",
    "Start by importing the simulator data from the training_data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset Parameters\n",
    "DRIVING_LOG_CSV = 'driving_log.csv'\n",
    "MODEL_DATA = 'model.h5'\n",
    "\n",
    "# Image Augmentation\n",
    "CORRECTION_ANGLE = 0.25\n",
    "NB_AUGMENTED_SAMPLES = 5000\n",
    "\n",
    "# Image Processing\n",
    "DEFAULT_LENGTH, DEFAULT_WIDTH, DEFAULT_DEPTH = (64, 64, 3)\n",
    "DEFAULT_RESOLUTION = (DEFAULT_LENGTH, DEFAULT_WIDTH, DEFAULT_DEPTH) if DEFAULT_DEPTH > 1 else (DEFAULT_LENGTH, DEFAULT_WIDTH)\n",
    "DATASET_DIRECTORY = 'merged_data/'\n",
    "\n",
    "# Validation Dataset\n",
    "VALIDATION_PORTION = 0.222"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset - Image Augmentation\n",
    "\n",
    "Image Augmentation techniques as described by Vivek Yadav (https://chatbotslife.com/using-augmentation-to-mimic-human-driving-496b569760a9#.jao9k5lb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def read_csv(filepath, num_features=7, delimiter=';'):\n",
    "    data_array = np.array(np.zeros(shape=num_features), ndmin=2)    \n",
    "    with open(filepath, newline='') as csvfile:\n",
    "        annotations_reader = csv.reader(csvfile, delimiter=delimiter, quotechar='|')\n",
    "        for row in annotations_reader:\n",
    "            data_array = np.vstack((data_array, np.array(row, ndmin=2)))\n",
    "    return data_array[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_brightness_camera_images(image):\n",
    "    image1 = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    random_bright = .25+np.random.uniform()\n",
    "    print(random_bright)\n",
    "    image1[:,:,2] = image1[:,:,2]*random_bright\n",
    "    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)\n",
    "    return image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_image(image,steer,trans_range):\n",
    "    # Translation\n",
    "    delta_x = trans_range*np.random.uniform()-trans_range/2\n",
    "    steering_angle = steer + delta_x/trans_range*2*.2\n",
    "    delta_y = 40*np.random.uniform()-40/2\n",
    "    Trans_M = np.float32([[1,0,delta_x],[0,1,delta_y]])\n",
    "    translated_image = cv2.warpAffine(image,Trans_M,(DEFAULT_LENGTH,DEFAULT_WIDTH))\n",
    "    \n",
    "    return translated_image,steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def randomly_add_shadow_effect(image):\n",
    "    top_y = 320*np.random.uniform()\n",
    "    top_x = 0\n",
    "    bot_x = 160\n",
    "    bot_y = 320*np.random.uniform()\n",
    "    image_hls = cv2.cvtColor(image,cv2.COLOR_RGB2HLS)\n",
    "    shadow_mask = 0*image_hls[:,:,1]\n",
    "    X_m = np.mgrid[0:image.shape[0],0:image.shape[1]][0]\n",
    "    Y_m = np.mgrid[0:image.shape[0],0:image.shape[1]][1]\n",
    "    shadow_mask[((X_m-top_x)*(bot_y-top_y) -(bot_x - top_x)*(Y_m-top_y) >=0)]=1\n",
    "    if np.random.randint(2)==1:\n",
    "        random_bright = .5\n",
    "        cond1 = shadow_mask==1\n",
    "        cond0 = shadow_mask==0\n",
    "        if np.random.randint(2)==1:\n",
    "            image_hls[:,:,1][cond1] = image_hls[:,:,1][cond1]*random_bright\n",
    "        else:\n",
    "            image_hls[:,:,1][cond0] = image_hls[:,:,1][cond0]*random_bright    \n",
    "    return cv2.cvtColor(image_hls,cv2.COLOR_HLS2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def resize_image(filepath):\n",
    "    if os.path.exists(filepath):\n",
    "        print('filepath', filepath)\n",
    "        image = cv2.imread(filepath)\n",
    "        print(image.shape)\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        shape = image.shape\n",
    "        image = image[math.floor(shape[0]/5):shape[0]-25, 0:shape[1]] #Crop image to remove extraneous pixels\n",
    "        \n",
    "        if (shape[0] != DEFAULT_RESOLUTION[1] or shape[1] != DEFAULT_RESOLUTION[0]):\n",
    "            image = cv2.resize(image,(DEFAULT_RESOLUTION[1],DEFAULT_RESOLUTION[0]), interpolation=cv2.INTER_AREA)\n",
    "    else:\n",
    "        print(\"File {0} does not exist! Skipping..\".format(filepath))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomly_flip_image(image, measurement):\n",
    "    if (np.random.randint(2) == 0):\n",
    "        image = cv2.flip(image,1)\n",
    "        measurement = -measurement\n",
    "    return image, measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_image(line_data):\n",
    "    random_index = np.random.randint(3)    \n",
    "    if (random_index == 0):\n",
    "        filepath = line_data['left'][0].strip()\n",
    "        shifted_ang = CORRECTION_ANGLE\n",
    "    if (random_index == 1):\n",
    "        filepath = line_data['center'][0].strip()\n",
    "        shifted_ang = 0.\n",
    "    if (random_index == 2):\n",
    "        filepath = line_data['right'][0].strip()\n",
    "        shifted_ang = -CORRECTION_ANGLE\n",
    "            \n",
    "    full_path = os.path.join(DATASET_DIRECTORY, filepath.strip())\n",
    "    if os.path.exists(full_path):\n",
    "        image = resize_image(full_path)\n",
    "        steering_angle = float(line_data['steering'][0]) + shifted_ang\n",
    "        image = randomly_add_shadow_effect(image)\n",
    "        image, steering_angle = translate_image(image, steering_angle, 100)\n",
    "        image = augment_brightness_camera_images(image)\n",
    "        image, steering_angle = randomly_flip_image(image, steering_angle)\n",
    "    else:\n",
    "        print('Image Path:', full_path, \"does not exist\")\n",
    "\n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "def generate_augmented_training_batch(pr_threshold = 1, batch_size = 256):\n",
    "    data=pd.read_csv(os.path.join(DATASET_DIRECTORY, DRIVING_LOG_CSV))\n",
    "    \n",
    "    batch_images = np.zeros((batch_size, DEFAULT_RESOLUTION[0], DEFAULT_RESOLUTION[1], DEFAULT_RESOLUTION[2]))\n",
    "    batch_steering = np.zeros(batch_size)\n",
    "    while 1:\n",
    "        for i_batch in range(batch_size):\n",
    "            index = np.random.randint(len(annotations))    \n",
    "            line_data = data.iloc[[index]].reset_index()\n",
    "            keep_pr = 0\n",
    "            while keep_pr == 0:\n",
    "                image, measurement = preprocess_image(line_data)\n",
    "                pr_unif = np.random\n",
    "                if (abs(measurement) < .1):\n",
    "                    pr_val = np.random.uniform()\n",
    "                    if (pr_val > pr_threshold):\n",
    "                        keep_pr = 1\n",
    "                else:\n",
    "                    keep_pr = 1\n",
    "            \n",
    "            batch_images[i_batch] = image\n",
    "            batch_steering[i_batch] = measurement\n",
    "        yield batch_images, batch_steering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Network - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation, Lambda\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import SGD, Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Cropping2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#Hyperparameters\n",
    "batch_size = 128\n",
    "nb_epochs = 2\n",
    "\n",
    "inputs = Input(shape=DEFAULT_RESOLUTION)\n",
    "#crop = Cropping2D(cropping=((top_c65rop,bottom_crop), (0,0)))(inputs)\n",
    "lambda_1 = Lambda(lambda x: x/127.5 - 1.)(inputs)\n",
    "conv_1 = Convolution2D(16, 8, 8, init='glorot_uniform',\n",
    "                             subsample=(4,4),border_mode='same')(lambda_1)\n",
    "lrelu_1 = LeakyReLU()(conv_1)\n",
    "conv_2 = Convolution2D(32, 5, 5, init='glorot_uniform',\n",
    "                             subsample=(2,2),border_mode='same')(lrelu_1)\n",
    "lrelu_2 = LeakyReLU()(conv_2)\n",
    "conv_3 = Convolution2D(64, 5, 5, init='glorot_uniform',\n",
    "                             subsample=(2,2),border_mode='same')(lrelu_1)\n",
    "flatten = Flatten()(conv_3)\n",
    "dropout_1 = Dropout(0.2)(flatten)\n",
    "lrelu_3 = LeakyReLU()(dropout_1)\n",
    "fc_1 = Dense(512)(lrelu_3)\n",
    "dropout_2 = Dropout(0.5)(fc_1)\n",
    "lrelu_4 = LeakyReLU()(dropout_2)\n",
    "predictions = Dense(1, activation='tanh')(lrelu_4)\n",
    "\n",
    "model = Model(input=inputs, output=predictions)\n",
    "adam = Adam(lr=0.0007, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='mse',\n",
    "             optimizer=adam,\n",
    "             metrics=['msle'])\n",
    "print(model.summary())\n",
    "\n",
    "callback1 = ModelCheckpoint('weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss',\n",
    "                            verbose=0, save_best_only=False, mode='auto')\n",
    "\n",
    "pr_threshold = 1\n",
    "for epoch in range(nb_epochs):\n",
    "\n",
    "    generator = generate_augmented_training_batch(pr_threshold, batch_size)\n",
    "    validation_generator = generate_augmented_training_batch(batch_size)\n",
    "    validation_size = int(NB_AUGMENTED_SAMPLES*VALIDATION_PORTION)\n",
    "    \n",
    "    model.fit_generator(generator, samples_per_epoch=NB_AUGMENTED_SAMPLES,\n",
    "                    nb_epoch=1, callbacks=[callback1], validation_data=validation_generator,\n",
    "                   nb_val_samples = validation_size, verbose=1)\n",
    "    pr_threshold = 1/((epoch+1)*1.)\n",
    "\n",
    "model.save(MODEL_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [sdc_dev]",
   "language": "python",
   "name": "Python [sdc_dev]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
