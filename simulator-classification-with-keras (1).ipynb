{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset - Load Data\n",
    "\n",
    "Start by importing the simulator data from the training_data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset Parameters\n",
    "DRIVING_LOG_CSV = 'full_driving_log.csv'\n",
    "MODEL_DATA = 'model.h5'\n",
    "\n",
    "# Image Augmentation\n",
    "CORRECTION_ANGLE = 0.25\n",
    "NB_AUGMENTED_SAMPLES = 1000\n",
    "\n",
    "# Image Processing\n",
    "DEFAULT_LENGTH, DEFAULT_WIDTH, DEFAULT_DEPTH = (64, 64, 3)\n",
    "DEFAULT_RESOLUTION = (DEFAULT_LENGTH, DEFAULT_WIDTH, DEFAULT_DEPTH) if DEFAULT_DEPTH > 1 else (DEFAULT_LENGTH, DEFAULT_WIDTH)\n",
    "DATASET_DIRECTORY = 'merged_data/'\n",
    "\n",
    "# Validation Dataset\n",
    "VALIDATION_PORTION = 0.222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drive_data = pd.read_csv(os.path.join(DATASET_DIRECTORY,DRIVING_LOG_CSV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>steering</th>\n",
       "      <th>throttle</th>\n",
       "      <th>brake</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG/center_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.148290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG/center_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.879630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.453011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.438419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.418236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   center  \\\n",
       "0  IMG/center_2016_12_01_13_30_48_287.jpg   \n",
       "1  IMG/center_2016_12_01_13_30_48_404.jpg   \n",
       "2  IMG/center_2016_12_01_13_31_12_937.jpg   \n",
       "3  IMG/center_2016_12_01_13_31_13_037.jpg   \n",
       "4  IMG/center_2016_12_01_13_31_13_177.jpg   \n",
       "\n",
       "                                    left  \\\n",
       "0   IMG/left_2016_12_01_13_30_48_287.jpg   \n",
       "1   IMG/left_2016_12_01_13_30_48_404.jpg   \n",
       "2   IMG/left_2016_12_01_13_31_12_937.jpg   \n",
       "3   IMG/left_2016_12_01_13_31_13_037.jpg   \n",
       "4   IMG/left_2016_12_01_13_31_13_177.jpg   \n",
       "\n",
       "                                    right  steering  throttle  brake  \\\n",
       "0   IMG/right_2016_12_01_13_30_48_287.jpg       0.0       0.0    0.0   \n",
       "1   IMG/right_2016_12_01_13_30_48_404.jpg       0.0       0.0    0.0   \n",
       "2   IMG/right_2016_12_01_13_31_12_937.jpg       0.0       0.0    0.0   \n",
       "3   IMG/right_2016_12_01_13_31_13_037.jpg       0.0       0.0    0.0   \n",
       "4   IMG/right_2016_12_01_13_31_13_177.jpg       0.0       0.0    0.0   \n",
       "\n",
       "       speed  \n",
       "0  22.148290  \n",
       "1  21.879630  \n",
       "2   1.453011  \n",
       "3   1.438419  \n",
       "4   1.418236  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drive_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset - Image Augmentation\n",
    "\n",
    "Image Augmentation techniques as described by Vivek Yadav (https://chatbotslife.com/using-augmentation-to-mimic-human-driving-496b569760a9#.jao9k5lb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def read_csv(filepath, num_features=7, delimiter=';'):\n",
    "    data_array = np.array(np.zeros(shape=num_features), ndmin=2)    \n",
    "    with open(filepath, newline='') as csvfile:\n",
    "        annotations_reader = csv.reader(csvfile, delimiter=delimiter, quotechar='|')\n",
    "        for row in annotations_reader:\n",
    "            data_array = np.vstack((data_array, np.array(row, ndmin=2)))\n",
    "    return data_array[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_image(image):\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    shape = image.shape\n",
    "    image = image[math.floor(shape[0]/5):shape[0]-25, 0:shape[1]] #Crop image to remove extraneous pixels\n",
    "\n",
    "    if (shape[0] != DEFAULT_RESOLUTION[1] or shape[1] != DEFAULT_RESOLUTION[0]):\n",
    "        image = cv2.resize(image,(DEFAULT_RESOLUTION[1],DEFAULT_RESOLUTION[0]), interpolation=cv2.INTER_AREA)\n",
    "    else:\n",
    "        print(\"File {0} does not exist! Skipping..\".format(filepath))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_brightness_camera_images(image):\n",
    "    v_ch = 2\n",
    "    image1 = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    random_light = .25+np.random.uniform()\n",
    "    image1[:,:,v_ch] = image1[:,:,v_ch]*random_light\n",
    "    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)\n",
    "    return image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def translate_image(image,steer,trans_range):\n",
    "    # Translation\n",
    "    delta_x = trans_range*np.random.uniform()-trans_range/2\n",
    "    steering_angle = steer + delta_x/trans_range*2*.2\n",
    "    delta_y = 40*np.random.uniform()-40/2\n",
    "    Trans_M = np.float32([[1,0,delta_x],[0,1,delta_y]])\n",
    "    translated_image = cv2.warpAffine(image,Trans_M,(DEFAULT_WIDTH, DEFAULT_LENGTH))\n",
    "    \n",
    "    cv2.imshow('image', translated_image)\n",
    "    \n",
    "    return translated_image,steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def randomly_add_shadow_effect(image):\n",
    "    top_y = DEFAULT_LENGTH*np.random.uniform()\n",
    "    top_x = 0\n",
    "    bot_x = DEFAULT_WIDTH\n",
    "    bot_y = DEFAULT_LENGTH*np.random.uniform()\n",
    "    s_ch = 1\n",
    "    image_hls = cv2.cvtColor(image,cv2.COLOR_RGB2HLS) #HLS\n",
    "    shadow_mask = 0*image_hls[:,:,1]\n",
    "    X_m = np.mgrid[0:image.shape[0],0:image.shape[1]][0]\n",
    "    Y_m = np.mgrid[0:image.shape[0],0:image.shape[1]][1]\n",
    "    shadow_mask[((X_m-top_x)*(bot_y-top_y) -(bot_x - top_x)*(Y_m-top_y) >=0)]=1\n",
    "    if np.random.randint(2)==1:\n",
    "        random_bright = .5\n",
    "        cond1 = shadow_mask==1\n",
    "        cond0 = shadow_mask==0\n",
    "        if np.random.randint(2)==1:\n",
    "            image_hls[:,:,s_ch][cond1] = image_hls[:,:,s_ch][cond1]*random_bright\n",
    "        else:\n",
    "            image_hls[:,:,s_ch][cond0] = image_hls[:,:,s_ch][cond0]*random_bright    \n",
    "    return cv2.cvtColor(image_hls,cv2.COLOR_HLS2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomly_flip_image(image, measurement):\n",
    "    if (np.random.randint(2) == 0):\n",
    "        image = cv2.flip(image,1)\n",
    "        measurement = -measurement\n",
    "    return image, measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_image(line_data, scaled_features):    \n",
    "    random_index = np.random.randint(3)    \n",
    "    if (random_index == 0):\n",
    "        filepath = line_data['left'][0].strip()\n",
    "        shifted_ang = CORRECTION_ANGLE\n",
    "    if (random_index == 1):\n",
    "        filepath = line_data['center'][0].strip()\n",
    "        shifted_ang = 0.\n",
    "    if (random_index == 2):\n",
    "        filepath = line_data['right'][0].strip()\n",
    "        shifted_ang = -CORRECTION_ANGLE\n",
    "            \n",
    "    full_path = os.path.join(DATASET_DIRECTORY, filepath.strip())\n",
    "    if os.path.exists(full_path):\n",
    "        image = cv2.imread(full_path)\n",
    "        image = resize_image(image)\n",
    "        \n",
    "        #Scale Steering Angle back up\n",
    "        mean, std = scaled_features['steering']\n",
    "        steering_angle = float(line_data['steering'][0])*std + mean + shifted_ang\n",
    "        #image = randomly_add_shadow_effect(image)\n",
    "        image, steering_angle = translate_image(image, steering_angle, 100)\n",
    "        #image = augment_brightness_camera_images(image)\n",
    "        image, steering_angle = randomly_flip_image(image, steering_angle)\n",
    "    else:\n",
    "        print('Image Path:', full_path, \"does not exist\")\n",
    "\n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling target variables\n",
    "To make training the network easier, we'll standardize each of the continuous variables. That is, we'll shift and scale the variables such that they have zero mean and a standard deviation of 1.\n",
    "\n",
    "The scaling factors are saved so we can go backwards when we use the network for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def cache_scaled_features(scaled_features = {}):\n",
    "    \n",
    "#     if scaled_features is None:\n",
    "        \n",
    "#     else:\n",
    "#         quant_features = ['steering', 'throttle','brake','speed']\n",
    "\n",
    "#         # Store scalings in a dictionary for converting back later\n",
    "#         for each in quant_features:\n",
    "#             mean, std = data[each].mean(), data[each].std()\n",
    "#             scaled_features[each] = [mean, std]\n",
    "#             data.loc[:, each] = (data[each] - mean)/std\n",
    "\n",
    "#             # Separate the data into features and targets\n",
    "#             target_fields = ['steering', 'throttle', 'brake', 'speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def generate_augmented_training_batch(pr_threshold = 1, batch_size = 256):\n",
    "    data=pd.read_csv(os.path.join(DATASET_DIRECTORY, DRIVING_LOG_CSV))\n",
    "    quant_features = ['steering', 'throttle','brake','speed']\n",
    "    # Store scalings in a dictionary for converting back later\n",
    "    global scaled_features\n",
    "    features = {}\n",
    "    \n",
    "    for each in quant_features:\n",
    "        mean, std = data[each].mean(), data[each].std()\n",
    "\n",
    "        features[each] = [mean, std]\n",
    "        data.loc[:, each] = (data[each] - mean)/std\n",
    "        \n",
    "        # Separate the data into features and targets\n",
    "        target_fields = ['steering', 'throttle', 'brake', 'speed']\n",
    "        camera_data, sensor_data = data.drop(target_fields, axis=1), data[target_fields]\n",
    "        scaled_features = features\n",
    "    \n",
    "    batch_images = np.zeros((batch_size, DEFAULT_RESOLUTION[0], DEFAULT_RESOLUTION[1], DEFAULT_RESOLUTION[2]))\n",
    "    batch_measurements = np.zeros(batch_size)\n",
    "    while 1:\n",
    "        for i_batch in range(batch_size):\n",
    "            index = np.random.randint(len(data)) \n",
    "            line_data = data.iloc[[index]].reset_index()\n",
    "            keep_pr = 0\n",
    "            while keep_pr == 0:\n",
    "                print('scaled_features',scaled_features)\n",
    "                image, measurement = preprocess_image(line_data, scaled_features)\n",
    "                pr_unif = np.random\n",
    "                if (abs(measurement) < .1):\n",
    "                    pr_val = np.random.uniform()\n",
    "                    if (pr_val > pr_threshold):\n",
    "                        keep_pr = 1\n",
    "                else:\n",
    "                    keep_pr = 1\n",
    "            \n",
    "            batch_images[i_batch] = image\n",
    "            batch_measurements[i_batch] = measurement\n",
    "        yield batch_images, batch_measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Network - Modified Comma AI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 64, 64, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 64, 64, 3)     0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 16, 16, 16)    3088        lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_1 (LeakyReLU)          (None, 16, 16, 16)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 8, 8, 64)      25664       leakyrelu_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 4096)          0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4096)          0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_3 (LeakyReLU)          (None, 4096)          0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 512)           2097664     leakyrelu_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 512)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_4 (LeakyReLU)          (None, 512)           0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             513         leakyrelu_4[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 2,126,929\n",
      "Trainable params: 2,126,929\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/1\n",
      "scaled_features {'speed': [26.22270355500936, 7.309568159613813]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/deanmwebb/anaconda/envs/sdc_dev/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/deanmwebb/anaconda/envs/sdc_dev/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/deanmwebb/anaconda/envs/sdc_dev/lib/python3.5/site-packages/keras/engine/training.py\", line 429, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"<ipython-input-13-3627b087ddca>\", line 27, in generate_augmented_training_batch\n",
      "    image, measurement = preprocess_image(line_data, scaled_features)\n",
      "  File \"<ipython-input-11-71009f41adf9>\", line 19, in preprocess_image\n",
      "    mean, std = scaled_features['steering']\n",
      "KeyError: 'steering'\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-411f49af24a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     model.fit_generator(generator, samples_per_epoch=NB_AUGMENTED_SAMPLES,\n\u001b[1;32m     57\u001b[0m                     \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                    nb_val_samples = validation_size, verbose=1)\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mpr_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/deanmwebb/anaconda/envs/sdc_dev/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1530\u001b[0m                                          \u001b[0;34m'(x, y, sample_weight) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m                                          \u001b[0;34m'or (x, y). Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m                                          str(generator_output))\n\u001b[0m\u001b[1;32m   1533\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation, Lambda\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import SGD, Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Cropping2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#Hyperparameters\n",
    "batch_size = 256\n",
    "nb_epochs = 2\n",
    "top_crop = 65\n",
    "bottom_crop = 25\n",
    "\n",
    "inputs = Input(shape=(DEFAULT_RESOLUTION[0], DEFAULT_RESOLUTION[1], DEFAULT_RESOLUTION[2]))\n",
    "#crop = Cropping2D(cropping=((top_crop,bottom_crop), (0,0)))(inputs)\n",
    "lambda_1 = Lambda(lambda x: x/127.5 - 1.)(inputs)\n",
    "conv_1 = Convolution2D(16, 8, 8, init='glorot_uniform',\n",
    "                             subsample=(4,4),border_mode='same')(lambda_1)\n",
    "lrelu_1 = LeakyReLU()(conv_1)\n",
    "conv_2 = Convolution2D(32, 5, 5, init='glorot_uniform',\n",
    "                             subsample=(2,2),border_mode='same')(lrelu_1)\n",
    "lrelu_2 = LeakyReLU()(conv_2)\n",
    "conv_3 = Convolution2D(64, 5, 5, init='glorot_uniform',\n",
    "                             subsample=(2,2),border_mode='same')(lrelu_1)\n",
    "flatten = Flatten()(conv_3)\n",
    "dropout_1 = Dropout(0.2)(flatten)\n",
    "lrelu_3 = LeakyReLU()(dropout_1)\n",
    "fc_1 = Dense(512)(lrelu_3)\n",
    "dropout_2 = Dropout(0.5)(fc_1)\n",
    "lrelu_4 = LeakyReLU()(dropout_2)\n",
    "predictions = Dense(1, activation='tanh')(lrelu_4)\n",
    "\n",
    "model = Model(input=inputs, output=predictions)\n",
    "adam = Adam(lr=0.0007, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='mse',\n",
    "             optimizer=adam,\n",
    "             metrics=['msle'])\n",
    "print(model.summary())\n",
    "\n",
    "callback1 = ModelCheckpoint('weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss',\n",
    "                            verbose=0, save_best_only=False, mode='auto')        \n",
    "pr_threshold = 1\n",
    "for e in range(nb_epochs):\n",
    "    generator = generate_augmented_training_batch(pr_threshold, batch_size)\n",
    "    validation_generator = generate_augmented_training_batch(pr_threshold,batch_size)\n",
    "    validation_size = int(NB_AUGMENTED_SAMPLES*VALIDATION_PORTION)\n",
    "    \n",
    "    model.fit_generator(generator, samples_per_epoch=NB_AUGMENTED_SAMPLES,\n",
    "                    nb_epoch=1, callbacks=[callback1], validation_data=validation_generator,\n",
    "                   nb_val_samples = validation_size, verbose=1)\n",
    "    pr_threshold = 1/((e+1)*1.)\n",
    "\n",
    "model.save(MODEL_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [sdc_dev]",
   "language": "python",
   "name": "Python [sdc_dev]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
